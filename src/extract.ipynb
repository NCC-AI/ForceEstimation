{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as k\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from force_utils import DataProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = './dataset/video.mp4'\n",
    "csv_file = './dataset/forceinfo.csv'\n",
    "dataset = DataProcessing(video_file, csv_file, p=True, f=True, name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and validation\n",
    "keys = list(dataset.f_dict.keys())\n",
    "train_num = int(round(0.8 * len(keys)))\n",
    "train_keys = keys[:train_num]\n",
    "val_keys = keys[train_num:]\n",
    "val_num = len(val_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (299, 299, 3)\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_directory(train=True, batch_size=32):\n",
    "    while True:\n",
    "        x, y, i = [], [], 0\n",
    "        if train:\n",
    "            #random.shuffle(train_keys)\n",
    "            for image_file in train_keys:\n",
    "                image = load_img('dataset/frames/' + image_file, target_size=(input_shape[0], input_shape[1]))\n",
    "                image = img_to_array(image) \n",
    "                image /= 255.\n",
    "                x.append(image)\n",
    "                y.append(dataset.f_dict[image_file])\n",
    "                i += 1\n",
    "                if i == batch_size:\n",
    "                    yield (np.array(x), np.array(y))\n",
    "                    x, y, i = [], [], 0\n",
    "        else:\n",
    "            #random.shuffle(val_keys)\n",
    "            for image_file in val_keys:\n",
    "                image = load_img('dataset/frames/' + image_file, target_size=(input_shape[0], input_shape[1]))\n",
    "                image = img_to_array(image) \n",
    "                image /= 255.\n",
    "                x.append(image)\n",
    "                y.append(dataset.f_dict[image_file])\n",
    "                i += 1\n",
    "                if i == batch_size:\n",
    "                    yield (np.array(x), np.array(y))\n",
    "                    x, y, i = [], [], 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(include_top=False, weights='imagenet', input_tensor=Input(shape=input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1415/1415 [==============================] - 1340s 947ms/step\n"
     ]
    }
   ],
   "source": [
    "bottleneck_features_train = base_model.predict_generator(\n",
    "    generate_from_directory(True, 32),\n",
    "    steps=train_num//batch_size,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataset/features/dense_train.npy', bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_validation = base_model.predict_generator(\n",
    "    generate_from_directory(False, 32),\n",
    "    steps=val_num//batch_size,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataset/features/dense_val.npy', bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
