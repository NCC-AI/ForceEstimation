{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as k\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from force_utils import database, save_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make force_dic = {image_file_name : force_value}\n",
    "movie_file = 'dataset/movie.mp4'\n",
    "csv_file = 'dataset/forceinfo.csv'\n",
    "dataset = database(movie_file, csv_file)\n",
    "force = dataset.make_tension()\n",
    "frame_id, frames = dataset.make_inputs()\n",
    "force_dic = {}\n",
    "for i in range(len(frames)):\n",
    "    force_dic[frames[i]] = force[i]\n",
    "\n",
    "# Split train and validation\n",
    "keys = list(force_dic.keys())\n",
    "train_num = int(round(0.8 * len(keys)))\n",
    "train_keys = keys[:train_num]\n",
    "val_keys = keys[train_num:]\n",
    "val_num = len(val_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_train = np.load('dataset/features/vgg16_train.npy')\n",
    "bottleneck_features_validation = np.load('dataset/features/vgg16_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = bottleneck_features_train.copy()\n",
    "validation_data = bottleneck_features_validation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[:-112]\n",
    "x_test = validation_data[:-28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for image_file in train_keys:\n",
    "    y_train.append(force_dic[image_file])\n",
    "y_train = np.array(y_train)[:-82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "for image_file in val_keys:\n",
    "    y_test.append(force_dic[image_file])\n",
    "y_test = np.array(y_test)[:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45200, 9, 9, 512) (45200,) (11300, 9, 9, 512) (11300,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2260 565 9 9 512\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "epochs=100\n",
    "timesteps = 20\n",
    "train_samples = int(x_train.shape[0] / timesteps)\n",
    "validation_samples = int(x_test.shape[0] / timesteps)\n",
    "height, width, channel = x_train.shape[1], x_train.shape[2], x_train.shape[3]\n",
    "print(train_samples, validation_samples, height, width, channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2260, 20, 9, 9, 512) (565, 20, 9, 9, 512)\n"
     ]
    }
   ],
   "source": [
    "x_train_lstm = x_train.reshape(train_samples, timesteps, height, width, channel)\n",
    "x_test_lstm = x_test.reshape(validation_samples, timesteps, height, width, channel)\n",
    "print(x_train_lstm.shape, x_test_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2260, 1) (565, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train_lstm = y_train.reshape(train_samples, timesteps, 1)[:, -1]\n",
    "y_test_lstm = y_test.reshape(validation_samples, timesteps, 1)[:, -1]\n",
    "print(y_train_lstm.shape, y_test_lstm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(timesteps, height, width, channel))\n",
    "x = TimeDistributed(Flatten(input_shape=(height, width, channel)))(input_tensor)\n",
    "x = LSTM(512, return_sequences=False, dropout=0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "prediction = Dense(1)(x)\n",
    "model = Model(inputs=input_tensor, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 20, 9, 9, 512)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 20, 41472)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 512)               85985280  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 86,116,865\n",
      "Trainable params: 86,116,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optim = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint('dataset/weights/lstm_mae_{epoch:02d}.h5', monitor='val_loss', verbose=1, save_best_only=True),\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')]\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=optim, loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2260 samples, validate on 565 samples\n",
      "Epoch 1/100\n",
      "2260/2260 [==============================] - 26s 12ms/step - loss: 1.0354 - val_loss: 0.5334\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.53343, saving model to dataset/weights/lstm_mae_01.h5\n",
      "Epoch 2/100\n",
      "2260/2260 [==============================] - 21s 9ms/step - loss: 0.8712 - val_loss: 0.5585\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.53343\n",
      "Epoch 3/100\n",
      "2260/2260 [==============================] - 21s 9ms/step - loss: 0.8418 - val_loss: 0.9042\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.53343\n",
      "Epoch 4/100\n",
      "2260/2260 [==============================] - 21s 9ms/step - loss: 0.8114 - val_loss: 0.6785\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.53343\n",
      "Epoch 5/100\n",
      "2260/2260 [==============================] - 21s 9ms/step - loss: 0.7961 - val_loss: 0.5498\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.53343\n",
      "Epoch 6/100\n",
      "2260/2260 [==============================] - 21s 9ms/step - loss: 0.7784 - val_loss: 0.5661\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.53343\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train_lstm, y_train_lstm,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(x_test_lstm, y_test_lstm),\n",
    "    verbose=1)\n",
    "\n",
    "save_history(history, 'dataset/history/lstm_mae.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
